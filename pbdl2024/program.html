<!DOCTYPE html>
<html lang="en">
<head>
<title>Program</title>

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="description" content="Conference project">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="styles/bootstrap4/bootstrap.min.css">
<link href="plugins/font-awesome-4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="plugins/OwlCarousel2-2.2.1/owl.carousel.css">
<link rel="stylesheet" type="text/css" href="plugins/OwlCarousel2-2.2.1/owl.theme.default.css">
<link rel="stylesheet" type="text/css" href="plugins/OwlCarousel2-2.2.1/animate.css">
<link rel="stylesheet" type="text/css" href="styles/speakers.css">
<link rel="stylesheet" type="text/css" href="styles/speakers_responsive.css">
</head>
<body>

<div class="super_container">

	<!-- Menu -->

	<div class="menu trans_500">
		<div class="menu_content d-flex flex-column align-items-center justify-content-center text-center">
			<div class="menu_close_container"><div class="menu_close"></div></div>
			<div class="hamburger ml-auto"><i class="fa fa-bars" aria-hidden="true"></i></div>
			<ul>
				<li class="menu_item"><a href="preview_index.html">Home</a></li>
				<li class="menu_item"><a href="organizers">Organizers</a></li>
				<li class="menu_item"><a href="speakers">Speakers</a></li>
				<li class="menu_item"><a href="callforpapers">Call for papers</a></li>
				<li class="menu_item"><a href="./challenge/index.html">Challenge</a></li>
				<li class="menu_item"><a href="program.html">Program</a></li>
				<li class="menu_item"><a href="leaderboard.html">Leaderboard</a></li>
			</ul>
		</div>
	</div>

	<!-- Home -->

	<div class="home">
		<div class="parallax_background parallax-window" data-parallax="scroll" data-image-src="images/background.jpg" data-speed="0.8"></div>

		<!-- Header -->

		<header class="header" id="header">
				<div class="header_nav" id="header_nav_pin">
					<div class="header_nav_inner">
						<div class="header_nav_container">
							<div class="container">
								<div class="row">
									<div class="col">
										<div class="header_nav_content d-flex flex-row align-items-center justify-content-start">
											<nav class="main_nav">
												<ul>
													<li><a href="preview_index.html">Home</a></li>
													<li><a href="organizers.html">Organizers</a></li>
													<li><a href="speakers.html">Speakers</a></li>
													<li><a href="callforpapers.html">Call for papers</a></li>
													<li><a href="./challenge/index.html">Challenges</a></li>
													<li class="active"><a href="program.html">Program</a></li>
													<li><a href="leaderboard.html">Leaderboard</a></li>
												</ul>
											</nav>
										</div>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>	
		</header>
		
		<div class="home_content_container">
			<div class="container">
				<div class="row">
					<div class="col">
						<div class="home_content">
							<div class="home_date">The 4th International Workshop on</div>
							<div class="home_title"><font color="red">P</font>hysics <font color="red">B</font>ased Vision meets <font color="red">D</font>eep <font color="red">L</font>earning (PBDL)</div>
							
						</div>
					</div>
				</div>
			</div>
		</div>

		
	</div>

	<!-- Speakers -->

	 <div id="site_content">
      

	  <div id="content">
        <!-- insert the page content here -->
		<p style="color:black;font-size:20px;font-variant-numeric: lining-nums;"><b>PBDL2024 Tentative Schedules</b></p>
		<p style="color:black;font-size:16px;font-variant-numeric: lining-nums;"><b>Date: June 17, 2024</b></p>
		<p style="color:black;font-size:16px;font-variant-numeric: lining-nums;"><b>Location: Summit 333, Seattle Convention Center, Seattle WA, USA</b></p>

		<p style="color:black;font-size:16px;font-variant-numeric: lining-nums;"><b>Session 1: 8:30-10:00</b></p>
				
        <p style="color:black;font-size:15px;font-variant-numeric: lining-nums tabular-nums;">
			&ensp;&ensp;&ensp;&ensp;&ensp;Opening remark : (5min) <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;Keynote speaker 1 : Dr. Vladislav Golyanik, University of Kaiserslautern (40min) <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;Oral presentation 1-4 : (45min, 10 each with 5min buffer) <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;7	Generalized Foggy-Scene Semantic Segmentation by Frequency Decoupling <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;9	Generating Material-Aware 3D Models from Sparse Views <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;10	Physics Based Camera Privacy: Lens and Network Co-Design to the Rescue <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;19	Atlantis: Enabling Underwater Depth Estimation with Stable Diffusion (online) <br>
		</p>

		<p style="color:black;font-size:16px;font-variant-numeric: lining-nums;"><b>Coffee Break: 10:00-11:00</b></p>

		<p style="color:black;font-size:16px;font-variant-numeric: lining-nums;"><b>Session 2: 11:00-12:30</b></p>
				
        <p style="color:black;font-size:15px;font-variant-numeric: lining-nums tabular-nums;">
			&ensp;&ensp;&ensp;&ensp;&ensp;Keynote speaker 2: Prof. Tali Treibitz, University of Haifa (40min) <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;Oral presentation 5-9 (50min) <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;12	Imaging Signal Recovery Using Neural Network Priors Under Uncertain Forward Model Parameters <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;13	GPT4Motion: Scripting Physical Motions in Text-to-Video Generation via Blender-Oriented GPT Planning <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;15	Deep Learning for Computational Lens Design <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;3	Gain-first or Exposure-first: Benchmark for Better Low-light Video Photography and Enhancement (online) <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;4	Point-Supervised Semantic Segmentation of Natural Scenes via Hyperspectral Imaging (online) <br>
		</p>

		<p style="color:black;font-size:16px;font-variant-numeric: lining-nums;"><b>Lunch Break: 12:30-13:30</b></p>

		<p style="color:black;font-size:16px;font-variant-numeric: lining-nums;"><b>Session 3: 13:30-15:00</b></p>
				
        <p style="color:black;font-size:15px;font-variant-numeric: lining-nums tabular-nums;">
			&ensp;&ensp;&ensp;&ensp;&ensp;Competition session (40min) <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp; Introduction of the PBDL2024 Challenge <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp; Award <br>

			&ensp;&ensp;&ensp;&ensp;&ensp;Oral presentation 10-13 (40min) <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;20	Physics-Guided and Training-Free Diffusion for Controlling Illumination Conditions in Images <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;17	3D human pose and torque estimation from monocular video. <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;5	Computational Spectral Imaging with Unified Encoding Model and Beyond (online) <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;6	ViTKD: Feature-based Knowledge Distillation for Vision Transformers (online) <br>
			&ensp;&ensp;&ensp;&ensp;&ensp;Closing remark and best paper award (5min) <br>
		</p>

		<p style="color:black;font-size:16px;font-variant-numeric: lining-nums;"><b>Coffee Break: 15:00-16:00</b></p>

		<!-- <p style="color:black;font-size:16px;"><b>Schedule: EDT (Montreal time) (GMT-4)</b></p>
			<table style="width:100%; border-spacing:2;font-size:16px;font-variant-numeric: lining-nums;" >
			  <tbody><tr><th width="20%">Time</th> <th width="80%">Description</th></tr>
			  <tr><td>&nbsp;&nbsp;9:00-9:05</td><td>Welcome</td></tr>
			  <tr><td colspan="2">&nbsp;&nbsp;<strong>Session 1: 9:05 – 10:30</strong></td></tr>
			  <tr><td>&nbsp;&nbsp;9:05 - 9:15</td><td>Challenge Award Ceremony</td></tr>
			  <tr><td>&nbsp;&nbsp;9:15 - 9:45</td><td>Keynote 1 (physics based vision):</td></tr>
			  <tr><td>&nbsp;&nbsp;9:45 - 10:30</td><td>Oral Session 1 (15 min x 3)</td></tr> -->


			  <!-- <tr><td>&nbsp;&nbsp;8:15-8:30</td><td>Oral 2<br>Precise Forecasting of Sky Images Using Spatial Warping
				Leron K Julian (Carnegie Mellon University)*; Aswin Sankaranarayanan (Carnegie Mellon University)
				 </td></tr>
			  <tr><td>&nbsp;&nbsp;8:30-8:45</td><td>Oral 3<br>Enforcing Temporal Consistency in Video Depth Estimation
				Siyuan Li (Tencent)*; Yue Luo (Tencent); Ye Zhu (Tencent); Xun Zhao (Tencent Company); Yu Li (Tencent ); Ying Shan (Tencent)
				 </td></tr>
			  <tr><td>&nbsp;&nbsp;8:45-9:00</td><td>Oral 4<br>DeLiEve-Net: Deblurring Low-light Images with Light Streaks and Local Events
				Chu Zhou (Peking University)*; Minggui Teng (Peking University); Jin Han (Peking University); Chao Xu (Peking University); Boxin Shi (Peking University)
				 </td></tr>
			  <tr><td>&nbsp;&nbsp;9:00-9:15</td><td>Oral 5 <br>Efficient light transport acquisition by coded illumination and robust photometric stereo by dual photography using deep neural network
				Takafumi Iwaguchi (Kyushu Univ.)*; Hiroshi Kawasaki (Kyushu univ.)
				 </td></tr> -->

			  <!-- <tr><td colspan="2">&nbsp;&nbsp;<strong>Break and Poster Session (10-20 papers): 10:30 – 11:00</strong></td></tr>
			  <tr><td colspan="2">&nbsp;&nbsp;<strong>Session 2: 11:00 – 12:30</strong></td></tr>
			  <tr><td>&nbsp;&nbsp;11:00 – 11:30</td><td>Keynote 2 (machine learning)</td></tr>
			  <tr><td>&nbsp;&nbsp;11:30 – 12:15</td><td>Oral Session 2 (15 min x 3)</td></tr> -->


			  <!-- <tr><td>&nbsp;&nbsp;10:45 – 11:00</td><td>Oral 7<br> HyperMixNet: Hyperspectral Image Reconstruction with Deep Mixed Network from a Snapshot Measurement
				Kohei Yorimoto (Yamaguchi University); Xian-Hua Han (Yamaguchi University)*
				 </td></tr>
			  <tr><td>&nbsp;&nbsp;11:00 – 11:15</td><td>Oral 8<br> 	Generative Models for Multi-Illumination Color Constancy
				Partha Das (University of Amsterdam)*; Yang Liu (3DUniversum); Sezer Karaoglu (University of Amsterdam); Theo Gevers (University of Amsterdam)
				 </td></tr>
			  <tr><td>&nbsp;&nbsp;11:15 – 11:30</td><td>Oral 9<br> Multi-Level Adaptive Separable Convolution for Large-Motion Video Frame Interpolation 
				Ruth Wijma (University of Amsterdam)*; Shaodi You (University of Amsterdam); Yu Li (Tencnet)
				 </td></tr> -->


			  <!-- <tr><td>&nbsp;&nbsp;12:15 – 12:30</td><td>Best Paper Award and Closing Remarks</td></tr>
			</tbody></table> -->


		<!-- <p style="color:red;font-size:20px;">
			<br>
			The conference has ended. To view the recording, please go to <a href="https://m.bilibili.com/video/BV1G44y1x7Zw?share_medium=iphone&share_plat=ios&share_source=WEIXIN&share_tag=s_i&timestamp=1634047232&unique_k=Hi0ng6&share_times=1">link1</a> or <a href="https://www.youtube.com/watch?v=7CkHSSyP0uk">link2</a>.
			<br>
		</p> -->
		
		<!-- <p style="color:black;font-size:20px;"><b>Best Paper Award</b></p>

		<p style="color:rgb(39, 39, 39);font-size:13px;">
			<b>
				Efficient light transport acquisition by coded illumination and robust photometric stereo by dual photography using deep neural network
			</b>
		</p>
		<p style="color:rgb(39, 39, 39);font-size:13px;">
			<b>
			Takafumi Iwaguchi (Kyushu Univ.)*; Hiroshi Kawasaki (Kyushu univ.) 
			</b>
		</p> -->
      </div>
    </div>
</div>
<br><br><br>
<footer>
	<p style="font-variant-numeric: lining-nums;">If you have any questions, please feel free to contact us by sending an email to organizers <b style="color:blue">pbdl.ws@gmail.com</b> with title 'PBDL2024 website Inquiry'.</p>
</footer>

<script src="js/jquery-3.2.1.min.js"></script>
<script src="styles/bootstrap4/popper.js"></script>
<script src="styles/bootstrap4/bootstrap.min.js"></script>
<script src="plugins/OwlCarousel2-2.2.1/owl.carousel.js"></script>
<script src="plugins/easing/easing.js"></script>
<script src="plugins/parallax-js-master/parallax.min.js"></script>
<script src="js/speakers.js"></script>
</body>
</html>